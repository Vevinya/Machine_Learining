{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=pd.read_csv(\"Dataset/AllProductReviews-change.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>ReviewBody</th>\n",
       "      <th>ReviewStar</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Honest review of an edm music lover\\n</td>\n",
       "      <td>No doubt it has a great bass and to a great ex...</td>\n",
       "      <td>3</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unreliable earphones with high cost\\n</td>\n",
       "      <td>This  earphones are unreliable, i bought it be...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Really good and durable.\\n</td>\n",
       "      <td>i bought itfor 999,I purchased it second time,...</td>\n",
       "      <td>4</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>stopped working in just 14 days\\n</td>\n",
       "      <td>Its sound quality is adorable. overall it was ...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n</td>\n",
       "      <td>Its Awesome... Good sound quality &amp; 8-9 hrs ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                       ReviewTitle  \\\n",
       "0   1             Honest review of an edm music lover\\n   \n",
       "1   2             Unreliable earphones with high cost\\n   \n",
       "2   3                        Really good and durable.\\n   \n",
       "3   4                 stopped working in just 14 days\\n   \n",
       "4   5  Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n   \n",
       "\n",
       "                                          ReviewBody  ReviewStar  \\\n",
       "0  No doubt it has a great bass and to a great ex...           3   \n",
       "1  This  earphones are unreliable, i bought it be...           1   \n",
       "2  i bought itfor 999,I purchased it second time,...           4   \n",
       "3  Its sound quality is adorable. overall it was ...           1   \n",
       "4  Its Awesome... Good sound quality & 8-9 hrs ba...           5   \n",
       "\n",
       "            Product  \n",
       "0  boAt Rockerz 255  \n",
       "1  boAt Rockerz 255  \n",
       "2  boAt Rockerz 255  \n",
       "3  boAt Rockerz 255  \n",
       "4  boAt Rockerz 255  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['review'] = data_frame['ReviewTitle']+data_frame[\"ReviewBody\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=data_frame.drop([\"ReviewTitle\",\"ReviewBody\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14337 entries, 0 to 14336\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          14337 non-null  int64 \n",
      " 1   ReviewStar  14337 non-null  int64 \n",
      " 2   Product     14337 non-null  object\n",
      " 3   review      14337 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 560.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Remove the review that contains no text\n",
    "data_frame = data_frame[data_frame['review'] != '']\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making all review to lowercase\n",
    "data_frame['review'] = data_frame['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['rating'] = [str(1) if rating > 3 else str(0) for rating in data_frame['ReviewStar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=data_frame.drop([\"ReviewStar\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9402\n",
       "0    4935\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID         0\n",
       "Product    0\n",
       "review     0\n",
       "rating     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if the dataset contains null values\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split string to tokens and removing punctuation\n",
    "def identify_tokens(row):\n",
    "    tokens = nltk.word_tokenize(row)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of DataFrame\n",
    "data_frame['review'] = data_frame[\"review\"].apply(identify_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion for lemmatizing the list of words\n",
    "def stem_list(row):\n",
    "    lem_list = [lemmatizer.lemmatize(word) for word in row]\n",
    "    return (lem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming of the dataframe\n",
    "data_frame['review'] = data_frame[\"review\"].apply(stem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "stops.remove(\"not\")\n",
    "stops.remove(\"but\")\n",
    "stops.remove(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove stop words from the list of words\n",
    "def remove_stops(row):\n",
    "    meaningful_words = [w for w in row if not w in stops]\n",
    "    return (meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from the Dataframe\n",
    "data_frame['review'] = data_frame[\"review\"].apply(remove_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to join the processed words\n",
    "def rejoin_words(row):\n",
    "    joined_words = ( \" \".join(row))\n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the processed words in the data_frame\n",
    "data_frame['review'] = data_frame[\"review\"].apply(rejoin_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "      <td>honest review edm music lover no doubt ha grea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "      <td>unreliable earphone high cost earphone unrelia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "      <td>really good durable bought itfor purchased sec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "      <td>stopped working day sound quality adorable ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "      <td>awesome wireless headphone awesome good sound ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           Product                                             review  \\\n",
       "0   1  boAt Rockerz 255  honest review edm music lover no doubt ha grea...   \n",
       "1   2  boAt Rockerz 255  unreliable earphone high cost earphone unrelia...   \n",
       "2   3  boAt Rockerz 255  really good durable bought itfor purchased sec...   \n",
       "3   4  boAt Rockerz 255  stopped working day sound quality adorable ove...   \n",
       "4   5  boAt Rockerz 255  awesome wireless headphone awesome good sound ...   \n",
       "\n",
       "  rating  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_frame.iloc[:,2].values\n",
    "y=data_frame.iloc[:,3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X contains review, y contains the ratings\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 1,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10752,), (3585,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'0': 3687, '1': 7065}), Counter({'0': 1248, '1': 2337}))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model_nb = Pipeline([('tfifd',TfidfVectorizer()),\n",
    "                       ('model', MultinomialNB())\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfifd',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('model',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model_svc = Pipeline([('tfifd',TfidfVectorizer()),\n",
    "                       ('model', SVC())\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfifd',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('model',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.58      0.71      1248\n",
      "           1       0.81      0.97      0.89      2337\n",
      "\n",
      "    accuracy                           0.84      3585\n",
      "   macro avg       0.86      0.78      0.80      3585\n",
      "weighted avg       0.85      0.84      0.83      3585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_nb = text_model_nb.predict(X_test)\n",
    "print(classification_report(y_test, predictions_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 728  520]\n",
      " [  67 2270]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8362622036262204\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predictions_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.84      1248\n",
      "           1       0.91      0.94      0.92      2337\n",
      "\n",
      "    accuracy                           0.90      3585\n",
      "   macro avg       0.89      0.88      0.88      3585\n",
      "weighted avg       0.89      0.90      0.89      3585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_svc = text_model_svc.predict(X_test)\n",
    "print(classification_report(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1018  230]\n",
      " [ 144 2193]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956764295676429\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
